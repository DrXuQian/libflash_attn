[  7%] Building CUDA object CMakeFiles/flash_attn.dir/src/flash.cu.o
[ 14%] Building CUDA object CMakeFiles/flash_attn.dir/src/flash_fwd_hdim64_fp16_sm90.cu.o
[ 21%] Building CUDA object CMakeFiles/flash_attn.dir/src/flash_fwd_hdim96_fp16_sm90.cu.o
[ 28%] Building CUDA object CMakeFiles/flash_attn.dir/src/flash_fwd_hdim128_fp16_sm90.cu.o
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137306; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137311; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137467; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137472; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137527; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137532; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137634; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137639; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137694; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137699; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137788; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137793; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137848; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137853; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137921; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_0001899c_00000000-6_flash_fwd_hdim128_fp16_sm90.ptx, line 137926; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
[ 35%] Building CUDA object CMakeFiles/flash_attn.dir/src/flash_fwd_hdim192_fp16_sm90.cu.o
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170209; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170214; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170219; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170380; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170385; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170390; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170445; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170450; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170455; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170557; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170562; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170567; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170622; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170627; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170632; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170721; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170726; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170731; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170786; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170791; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170796; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170864; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170869; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018ba1_00000000-6_flash_fwd_hdim192_fp16_sm90.ptx, line 170874; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
[ 42%] Building CUDA object CMakeFiles/flash_attn.dir/src/flash_fwd_hdim256_fp16_sm90.cu.o
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170108; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170113; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170118; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170123; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170289; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170294; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170299; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170304; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170359; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170364; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170369; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170374; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170476; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170481; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170486; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170491; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170546; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170551; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170556; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170561; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170650; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170655; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170660; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170665; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170720; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170725; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170730; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170735; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170803; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170808; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170813; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
ptxas /tmp/tmpxft_00018e18_00000000-6_flash_fwd_hdim256_fp16_sm90.ptx, line 170818; warning : Advisory: '.multicast::cluster' modifier on instruction 'cp.async.bulk{.tensor}' should be used on .target 'sm_90a/sm_100a/sm_101a' instead of .target 'sm_90' as this feature is expected to have substantially reduced performance on some future architectures
[ 50%] Building CUDA object CMakeFiles/flash_attn.dir/src/flash_fwd_hdim64_e4m3_sm90.cu.o
[ 57%] Building CUDA object CMakeFiles/flash_attn.dir/src/flash_fwd_hdim128_e4m3_sm90.cu.o
[ 64%] Building CUDA object CMakeFiles/flash_attn.dir/src/flash_fwd_hdim256_e4m3_sm90.cu.o
[ 71%] Building CUDA object CMakeFiles/flash_attn.dir/hopper/flash_prepare_scheduler.cu.o
[ 78%] Building CUDA object CMakeFiles/flash_attn.dir/hopper/flash_fwd_combine.cu.o
In file included from /home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu:4:
/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine_launch_template.h:16:10: fatal error: flash_fwd_combine_kernel.h: No such file or directory
   16 | #include "flash_fwd_combine_kernel.h"
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
In file included from /home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu:4:
/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine_launch_template.h:16:10: fatal error: flash_fwd_combine_kernel.h: No such file or directory
   16 | #include "flash_fwd_combine_kernel.h"
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
fatal   : Could not open input file /tmp/tmpxft_000197f8_00000000-7_flash_fwd_combine.cpp1.ii
make[2]: *** [CMakeFiles/flash_attn.dir/build.make:216: CMakeFiles/flash_attn.dir/hopper/flash_fwd_combine.cu.o] Error 1
make[1]: *** [CMakeFiles/Makefile2:85: CMakeFiles/flash_attn.dir/all] Error 2
make: *** [Makefile:91: all] Error 2
Consolidate compiler generated dependencies of target flash_attn
[  7%] Building CUDA object CMakeFiles/flash_attn.dir/hopper/flash_fwd_combine.cu.o
/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine_launch_template.h(21): error: incomplete type "void" is not allowed
  void run_flash_fwd_combine(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl) {
       ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine_launch_template.h(21): error: identifier "Flash_fwd_params" is undefined
  void run_flash_fwd_combine(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl) {
                             ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine_launch_template.h(21): error: identifier "params" is undefined
  void run_flash_fwd_combine(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl) {
                                               ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine_launch_template.h(21): error: type name is not allowed
  void run_flash_fwd_combine(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl) {
                                                       ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine_launch_template.h(21): error: expected a ")"
  void run_flash_fwd_combine(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl) {
                                                                    ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine_launch_template.h(21): error: expected a ";"
  void run_flash_fwd_combine(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl) {
                                                                                             ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(7): error: run_mha_fwd_combine_ is not a template
  template void run_mha_fwd_combine_<float, float, 128>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
                ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(7): error: "Flash_fwd_params" is not a type name
  template void run_mha_fwd_combine_<float, float, 128>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
                                                        ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(7): error: invalid explicit instantiation declaration
  template void run_mha_fwd_combine_<float, float, 128>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
           ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(9): error: run_mha_fwd_combine_ is not a template
  template void run_mha_fwd_combine_<cutlass::half_t, float, 64>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
                ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(9): error: "Flash_fwd_params" is not a type name
  template void run_mha_fwd_combine_<cutlass::half_t, float, 64>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
                                                                 ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(9): error: invalid explicit instantiation declaration
  template void run_mha_fwd_combine_<cutlass::half_t, float, 64>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
           ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(10): error: run_mha_fwd_combine_ is not a template
  template void run_mha_fwd_combine_<cutlass::half_t, float, 128>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
                ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(10): error: "Flash_fwd_params" is not a type name
  template void run_mha_fwd_combine_<cutlass::half_t, float, 128>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
                                                                  ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(10): error: invalid explicit instantiation declaration
  template void run_mha_fwd_combine_<cutlass::half_t, float, 128>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
           ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(12): error: run_mha_fwd_combine_ is not a template
  template void run_mha_fwd_combine_<cutlass::bfloat16_t, float, 64>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
                ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(12): error: "Flash_fwd_params" is not a type name
  template void run_mha_fwd_combine_<cutlass::bfloat16_t, float, 64>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
                                                                     ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(12): error: invalid explicit instantiation declaration
  template void run_mha_fwd_combine_<cutlass::bfloat16_t, float, 64>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
           ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(13): error: run_mha_fwd_combine_ is not a template
  template void run_mha_fwd_combine_<cutlass::bfloat16_t, float, 128>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
                ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(13): error: "Flash_fwd_params" is not a type name
  template void run_mha_fwd_combine_<cutlass::bfloat16_t, float, 128>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
                                                                      ^

/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu(13): error: invalid explicit instantiation declaration
  template void run_mha_fwd_combine_<cutlass::bfloat16_t, float, 128>(Flash_fwd_params &params, cudaStream_t stream, bool enable_pdl);
           ^

21 errors detected in the compilation of "/home/qianxu/flash-attention-homemade/libflash_attn/hopper/flash_fwd_combine.cu".
make[2]: *** [CMakeFiles/flash_attn.dir/build.make:216: CMakeFiles/flash_attn.dir/hopper/flash_fwd_combine.cu.o] Error 255
make[1]: *** [CMakeFiles/Makefile2:85: CMakeFiles/flash_attn.dir/all] Error 2
make: *** [Makefile:91: all] Error 2
